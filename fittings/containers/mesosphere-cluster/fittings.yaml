---

information:
  - "Mesosphere cluster with Docker, on 3 masters and 9 agents"
  - "A job submitted to Marathon is dispatched among agents."

parameters:

  locationId:
    information:
      - "the target data centre for this deployment"
    type: locations.list
    default: EU8

  regionId:
    information:
      - "the target data centre for this deployment"
    type: regions.list
    default: dd-eu

  domainName:
    information:
      - "the name of the network domain to be deployed"
    type: str
    default: MesosphereClusterFK

  networkName:
    information:
      - "the name of the Ethernet VLAN to be deployed"
    type: str
    default: MesosphereClusterNetworkFK

  cpuPerNode:
    information:
      - "the quantity of CPU given to one Mesos node"
    type: [4..32]
    default: 8

  memoryPerNode:
    information:
      - "the quantity of RAM given to one Mesos node, in GB"
    type: [8..256]
    default: 32

  diskPerNode:
    information:
      - "the quantity of storage given to one Mesos node, in GB"
    type: [100..1000]
    default: 500

links:
  documentation: https://github.com/DimensionDataCBUSydney/plumbery-contrib/tree/master/fittings/containers/mesosphere-cluster
  credit: https://open.mesosphere.com/getting-started/install/

defaults:

  # nodes are deployed in a single network domain
  domain:
    name: "{{ parameter.domainName }}"
    ipv4: auto

  # nodes are deployed on a single VLAN
  ethernet:
    name: "{{ parameter.networkName }}"
    subnet: 10.0.0.0

  # settings for any Meso master node
  mesosphere-master:

    information:
      - "a Mesosphere master node"
      - "connect remotely with:"
      - "$ ssh centos@{{ node.public }}"
      - "check Marathon interface at http://{{ node.public }}:8080/"
      - "check Mesos interface at http://{{ node.public }}:5050/"

    appliance: 'CentOS 7'

    cpu: 8
    memory: 32

    disks:
      - "1 100 standard"

    # :5050 is the Mesos web UI, :8080 is the Marathon web UI
    glue:
      - internet 22 5050 8080

    monitoring: essentials

    cloud-config:

      write_files:

        - path: /root/zoo.cfg.addition
          content: |
            server.1={{ master1.private }}:2888:3888
            server.2={{ master2.private }}:2888:3888
            server.3={{ master3.private }}:2888:3888

      runcmd:

        - echo "===== Installing Mesosphere"
        - rpm -Uvh http://repos.mesosphere.com/el/7/noarch/RPMS/mesosphere-el-repo-7-1.noarch.rpm
        - yum install -y mesos marathon mesosphere-zookeeper

        - echo "===== Configuring Zookeeper"
        - cp -n /etc/zookeeper/conf/zoo.cfg /etc/zookeeper/conf/zoo.cfg.orig
        - cat /etc/zookeeper/conf/zoo.cfg.orig /root/zoo.cfg.addition >/etc/zookeeper/conf/zoo.cfg

        - echo "===== Starting Zookeeper"
        - systemctl start zookeeper

        - echo "===== Configuring Mesos "

        - mkdir -p /etc/mesos-master
        - echo "{{ node.private }}" | tee /etc/mesos-master/ip

        # allow web redirection to leading master over public Internet
        - echo "{{ node.public }}" | tee /etc/mesos-master/hostname

        - echo "2" | tee /etc/mesos-master/quorum

        - mkdir -p /etc/mesos
        - sed -i "s/localhost:2181/{{ master1.private }}:2181,{{ master2.private }}:2181,{{ master3.private }}:2181/" /etc/mesos/zk

        - echo "===== Disabling Mesos slave service"
        - systemctl stop mesos-slave
        - systemctl disable mesos-slave

        - echo "===== Starting Mesos"
        - systemctl restart mesos-master

        - echo "===== Configuring Marathon"
        - mkdir -p /etc/marathon/conf
        - cp /etc/mesos-master/hostname /etc/marathon/conf
        - cp /etc/mesos/zk /etc/marathon/conf/master
        - echo "zk://{{ master1.private }}:2181,{{ master2.private }}:2181,{{ master3.private }}:2181/marathon" | tee /etc/marathon/conf/zk

        - echo "===== Starting Marathon"
        - systemctl restart marathon

  # settings for any Meso agent node
  mesosphere-agent:

    appliance: 'CentOS 7'

    cpu: "{{ parameter.cpuPerNode }}"
    memory: "{{ parameter.memoryPerNode }}"

    disks:
      - "1 {{ parameter.diskPerNode }} standard"

    glue:
      - internet 22

    monitoring: essentials

    cloud-config:

      runcmd:

        - echo "===== Installing Mesos"
        - rpm -Uvh http://repos.mesosphere.com/el/7/noarch/RPMS/mesosphere-el-repo-7-1.noarch.rpm
        - yum install -y mesos

        - echo "===== Configuring Mesos"

        - mkdir -p /etc/mesos-slave
        - echo "{{ node.private }}" | tee /etc/mesos-slave/ip
        - echo "{{ node.name }}" | tee /etc/mesos-slave/hostname

        # support docker containers as well
        - echo "docker,mesos" | tee /etc/mesos-slave/containerizers

        # afford long delays to pull a docker image
        - echo "5mins" | tee /etc/mesos-slave/executor_registration_timeout

        - mkdir -p /etc/mesos
        - sed -i "s/localhost:2181/{{ master1.private }}:2181,{{ master2.private }}:2181,{{ master3.private }}:2181/" /etc/mesos/zk

        - echo "===== Disabling Mesos master service"
        - systemctl stop mesos-master
        - systemctl disable mesos-master

        - echo "===== Starting Mesos"
        - systemctl start mesos-slave

  # a couple of directives for all nodes
  cloud-config:

    hostname: "{{ node.name }}"

    write_files:

      - path: /root/hosts.awk
        content: |
          #!/usr/bin/awk -f
          /^{{ master1.private }}/ {next}
          /^{{ master2.private }}/ {next}
          /^{{ master3.private }}/ {next}
          /^{{ node1.private }}/ {next}
          /^{{ node2.private }}/ {next}
          /^{{ node3.private }}/ {next}
          /^{{ node4.private }}/ {next}
          /^{{ node5.private }}/ {next}
          /^{{ node6.private }}/ {next}
          /^{{ node7.private }}/ {next}
          /^{{ node8.private }}/ {next}
          /^{{ node9.private }}/ {next}
          {print}
          END {
           print "{{ master1.private }}    master1"
           print "{{ master2.private }}    master2"
           print "{{ master3.private }}    master3"
           print "{{ node1.private }}    node1"
           print "{{ node2.private }}    node2"
           print "{{ node3.private }}    node3"
           print "{{ node4.private }}    node4"
           print "{{ node5.private }}    node5"
           print "{{ node6.private }}    node6"
           print "{{ node7.private }}    node7"
           print "{{ node8.private }}    node8"
           print "{{ node9.private }}    node9"
          }

      # use docker repo
      - path: /etc/yum.repos.d/docker.repo
        content: |
          [dockerrepo]
          name=Docker Repository
          baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/
          enabled=1
          gpgcheck=1
          gpgkey=https://yum.dockerproject.org/gpg

      # 'Mesos > 0.21.0' requires 'subversion > 1.8' devel package
      - path: /etc/yum.repos.d/wandisco-svn.repo
        content: |
          [WANdiscoSVN]
          name=WANdisco SVN Repo 1.9
          enabled=1
          baseurl=http://opensource.wandisco.com/centos/7/svn-1.9/RPMS/$basearch/
          gpgcheck=1
          gpgkey=http://opensource.wandisco.com/RPM-GPG-KEY-WANdisco

    packages:
      - ntp
      - wget
      - git
      - tar

    runcmd:

      - echo "===== Growing LVM with added disk"
      - pvcreate /dev/sdb
      - vgextend centos /dev/sdb
      - lvextend -l +100%FREE /dev/mapper/centos-root
      - xfs_growfs /dev/mapper/centos-root

      - echo "===== Handling centos identity"
      - cp -n /etc/ssh/ssh_host_rsa_key /home/centos/.ssh/id_rsa
      - cp -n /etc/ssh/ssh_host_rsa_key.pub /home/centos/.ssh/id_rsa.pub
      - chown centos:centos /home/centos/.ssh/*
      - sed -i "/StrictHostKeyChecking/s/^.*$/    StrictHostKeyChecking no/" /etc/ssh/ssh_config

      - echo "===== Updating /etc/hosts"
      - cp -n /etc/hosts /etc/hosts.original
      - awk -f /root/hosts.awk /etc/hosts >/etc/hosts.new && mv /etc/hosts.new /etc/hosts

      - echo "===== Installing EPEL"
      - wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo
      - yum install -y epel-release

      - echo "===== Updating systemd"
      - yum update systemd

      - echo "===== Installing essential development tools"
      - yum groupinstall -y "Development Tools"

      - echo "===== Installing other Mesos dependencies"
      - yum install -y apache-maven python-devel java-1.8.0-openjdk-devel zlib-devel libcurl-devel openssl-devel cyrus-sasl-devel cyrus-sasl-md5 apr-devel subversion-devel apr-util-devel

      - echo "===== Installing Docker Engine"
      - yum install -y docker-engine
      - systemctl start docker
      - docker pull python:3
      - docker pull hello-world

    ssh_keys:
      rsa_private: |
        {{ rsa_private.key }}
      rsa_public: "{{ rsa_public.key }}"

    users:
      - default

      - name: centos
        sudo: 'ALL=(ALL) NOPASSWD:ALL'
        ssh-authorized-keys:
          - "{{ rsa_public.key }}"
          - "{{ rsa_public.local }}"

    disable_root: true
    ssh_pwauth: false

---

# London - EU MCP 1 instance
regionId: "{{ parameter.regionId }}"
locationId: "{{ parameter.locationId }}"

blueprints:

  - masters:

      nodes:

        - master1:
            default: mesosphere-master

            cloud-config:

              write_files:

                - path: /var/lib/zookeeper/myid
                  content: |
                    1

                - path: /root/shell_hello.sh
                  content: |
                    #!/bin/bash
                    cd /root
                    curl {{ node.public }}:8080/v2/apps \
                    -H 'Content-Type: application/json' \
                    --include \
                    -d @/root/shell_hello.json

                - path: /root/shell_hello.json
                  content: |
                    {
                        "id": "shell-hello",
                        "cmd": "echo hello; sleep 10",
                        "mem": 16,
                        "cpus": 0.1,
                        "instances": 1,
                        "disk": 0.0,
                        "ports": [0]
                    }

                - path: /root/docker_hello.sh
                  content: |
                    #!/bin/bash
                    cd /root
                    curl {{ node.public }}:8080/v2/apps \
                    -H 'Content-Type: application/json' \
                    --include \
                    -d @/root/docker_hello.json

                - path: /root/docker_hello.json
                  content: |
                    {
                      "id": "docker-hello",
                      "cmd": "python3 -m http.server 8080",
                      "cpus": 0.5,
                      "mem": 32.0,
                      "container": {
                        "type": "DOCKER",
                        "docker": {
                          "image": "python:3",
                          "network": "BRIDGE",
                          "portMappings": [
                            { "containerPort": 8080, "hostPort": 0 }
                          ]
                        }
                      }
                    }

              runcmd:

                - echo "===== Waiting for system to be stable"
                - sleep 7m

                - echo "===== Submitting some activities to Marathon"
                - chmod +x /root/shell_hello.sh
                - /root/shell_hello.sh

                - echo "===== Submitting some activities to Docker"
                - chmod +x /root/docker_hello.sh
                - /root/docker_hello.sh

        - master2:
            default: mesosphere-master

            cloud-config:

              write_files:

                - path: /var/lib/zookeeper/myid
                  content: |
                    2

        - master3:
            default: mesosphere-master

            cloud-config:

              write_files:

                - path: /var/lib/zookeeper/myid
                  content: |
                    3

  - agents:

      nodes:
        - node[1..9]:
            default: mesosphere-agent
